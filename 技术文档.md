# 智序监控

1. 项目功能
   
   1. 

2. 项目架构
   为解决在各端在不同网络下的通信问题，本项目采用统一公网服务器，确保在任何情况下稳定连接，展示中使用的是一台阿里云上海集群的ecs.e-c1m1.large-Ubuntu 22.04 64位-40GiB ESSD Entry拥有固定公网ip的服务器
   为实现项目的可扩展性和可维护性，我们使用c/s架构，所有信息由服务器统一调度
   [画个导图中间是服务器，有rtmp流媒体服务器，mysql数据库和然后还有nodejs后端包含着{ai接口代理，数据库接口}，旁边分别连着harmony客户端，树莓派连着pwm控制sg90舵机和原装摄像头以及树莓派基于ffmpeg的rtmp推流，百度智能云api（两个分别为千帆大语言模型和人脸识别1:N大模型）]

3. 技术实现
   
   1. nodejs服务器，使用express框架实现所有子功能间的互联互通
   
   2. mysql
      本项目使用mysql5.7 （本来使用mysql8.0但是odbc的数据库query认证方式不适配node后端的库故回退到先前版本）使用对应的库实现数据的增删查改
      数据库结构如下（配上我在群里发的数据库sql）
   
   3. 百度智能云ai
      1.千帆大语言模型api实现 : 类似chat-gpt的大预言模型，在调用前会对用户发出的问题加上限定条件来优化反应速度和输出结果的正当性（咳嗽
      2.人脸1：N认证：各采集了小组同学的几十张图片上传至百度api实现1:N人脸认证
   
   4. 树莓派
      树莓派使用自行训练的AI模型判断是否有人，若有人则截图传至百度api得出人是谁并向对应用户数据库项记录当前计划完成状态
      树莓派使用pwm控制sg90舵机通过服务端中继实现，由于鸿蒙端socket在previewer和模拟器上出现一些问题，这里使用http轮询完成（在用户打开界面后每隔0.5s发送请求来实现基于半双工通信的实时摄像头姿态管理）
   
   5. rtmp推流服务器
      服务端使用基于nginx的流媒体服务器
      树莓派使用ffmpeg进行推流
      鸿蒙段使用基于web的webrtc协议进行拉流
   
   6. 鸿蒙端
      页面信息----反正这个你清楚我写几个重要的
      由于网络只使用http协议，包装了common_http(url,query)方法实现高拓展性、高复用性快捷前后端对接，以登录为例common_http('/login',{"username":"wrq","passwd:"****"})即可直接快捷实现数据的模块化传递
      rtmp拉流直接使用web()组件基于webrtc实时拉流，使用成熟的技术达到每秒20帧以上的帧率，（受树莓派硬件制约）,远优于传统的逐帧传输,(以2048byte的视频数据为一个单元，约有3s延迟换来连续稳定的图像)

4. 未来展望
   
   1. 使用鸿蒙提供的分布式文件系统在实现区中心化的系统，现在的系统高度依赖中心服务器，在推流时对服务企带宽要求极为苛刻，维护成本高，使用p2p能有效降低运维成本，提升用户体验，实现真正的高拓展和高可用。
   
   2. 解决socket通信问题，目前实现了python和nodejs的socket全双工通信，但是在鸿蒙端的问题暂时还没有解决，等研究成熟后可使用socket进行真正的全双工数据交换，提高稳定性和可维护性。
   
   3. 使用更强大的终端，本来希望树莓派可以运行自行使用yolo实现的1：N 但是受树莓派硬件制约，即使在关闭图形化界面的情况下单次识别仍然需要将近半分钟且会的整个系统的其他部分造成几乎毁灭性的影响，故作罢，希望换装算例更强筋且向树莓派尽量轻量化且拥有丰富IO接口的算力终端
